{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd0c5379",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T11:08:53.603346Z",
     "start_time": "2023-11-27T11:08:51.923957Z"
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6434c46",
   "metadata": {},
   "source": [
    "### model class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3481fc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T11:10:04.581437Z",
     "start_time": "2023-11-27T11:10:04.533335Z"
    }
   },
   "outputs": [],
   "source": [
    "class detections:\n",
    "    \n",
    "    def __init__(self):\n",
    "       \n",
    "        ### 변수\n",
    "        self.blink_flag = 0                # 눈 깜빡임 flag    \n",
    "        self.EAR = 0                       # 통합 EAR\n",
    "        self.PERCLOS = 0\n",
    "        self.PERCLOS_max = 0\n",
    "        self.PERCLOS_min = 0\n",
    "        self.level = 0                     # 현재 레벨\n",
    "        \n",
    "        self.default_EAR_ratio = 0.23 #0.17         # EAR 기준  0.35 ~ 0.2 사이의 80퍼센트 감김\n",
    "        \n",
    "        self.deafult_frame = 30\n",
    "        self.default_perclos_time = 60        # perclos 기준 시간\n",
    "        \n",
    "        self.limit_list_length = 1800 # self.deafult_frame * self.default_perclos_time # (1800 frames)\n",
    "                \n",
    "        self.status_Fatigue = 0.048\n",
    "        self.status_Drowsy = 0.125\n",
    "        self.status = 0\n",
    "        \n",
    "        self.blink_flag_list = [self.blink_flag]  # 커맨드 리스트\n",
    "\n",
    "            \n",
    "    def landmarks_detection(self, img, results, colors=utils.WHITE, landmark='All', draw=False):\n",
    "\n",
    "        img_height, img_width = img.shape[:2]\n",
    "        mesh_coord = [(int(point.x * img_width), int(point.y * img_height)) for point in results.multi_face_landmarks[0].landmark]\n",
    "\n",
    "        if landmark == 'All':\n",
    "            if draw:\n",
    "                [cv2.circle(img, p, 1, colors, -1) for p in mesh_coord]\n",
    "            return mesh_coord\n",
    "\n",
    "        else:\n",
    "            mark_coords = [mesh_coord[p] for p in landmark]\n",
    "            if draw:\n",
    "                [cv2.circle(img, p, 1, colors, -1) for p in mark_coords]\n",
    "            return mark_coords\n",
    "             \n",
    "                        \n",
    "    def calculate_ear(self, left_eye_coords, right_eye_coords):\n",
    "\n",
    "        # 눈 종횡비 계산\n",
    "        import math\n",
    "        from scipy.spatial import distance as dist\n",
    "\n",
    "        left_v1 = dist.euclidean(left_eye_coords[3], left_eye_coords[13])\n",
    "        left_v2 = dist.euclidean(left_eye_coords[5], left_eye_coords[11])\n",
    "        left_h = dist.euclidean(left_eye_coords[0], left_eye_coords[8])\n",
    "        \n",
    "        right_v1 = dist.euclidean(right_eye_coords[3], right_eye_coords[13])\n",
    "        right_v2 = dist.euclidean(right_eye_coords[5], right_eye_coords[11])\n",
    "        right_h = dist.euclidean(right_eye_coords[0], right_eye_coords[8])\n",
    "        \n",
    "        left_ear = round(((left_v1 + left_v2)/(2*left_h)), 4)\n",
    "        right_ear = round(((right_v1 + right_v2)/(2*right_h)), 4)\n",
    "        \n",
    "        EAR = round(((left_ear + right_ear)/2),3)\n",
    "        \n",
    "        if EAR < self.default_EAR_ratio :\n",
    "            self.EAR = EAR\n",
    "            self.blink_flag_list.append(1)\n",
    "        else:\n",
    "            self.EAR = EAR\n",
    "            self.blink_flag_list.append(0)\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def calculate_perclos(self):\n",
    "\n",
    "        if len(self.blink_flag_list) > self.limit_list_length :\n",
    "            self.blink_flag_list.pop(0)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        idx = 0; p1 = 0;\n",
    "\n",
    "        while idx < len(self.blink_flag_list):\n",
    "            if self.blink_flag_list[idx] == 0 and p1 == 0 :\n",
    "                idx = idx + 1\n",
    "                \n",
    "            elif self.blink_flag_list[idx] == 1 and p1 == 0 :\n",
    "                p1 = idx\n",
    "                idx = idx + 1\n",
    "                \n",
    "            elif self.blink_flag_list[idx] == 1 and p1 != 0 :\n",
    "                idx = idx + 1\n",
    "            \n",
    "            elif self.blink_flag_list[idx] == 0 and p1 != 0 :\n",
    "                if idx - p1 <= 6:\n",
    "                    for del_idx in range(p1, idx):\n",
    "                        self.blink_flag_list[del_idx] = 0\n",
    "                    p1 = 0\n",
    "                    idx = idx + 1  \n",
    "                else:\n",
    "                    idx = idx + 1\n",
    "                    p1 = 0\n",
    "\n",
    "        blink_moment = self.blink_flag_list.count(1)\n",
    "        #perclos = blink_moment/len(self.blink_flag_list)\n",
    "        perclos = blink_moment/self.limit_list_length\n",
    "        self.PERCLOS = perclos\n",
    "        \n",
    "        return\n",
    "            \n",
    "        \n",
    "    def calculate_level(self):\n",
    "                \n",
    "        if self.PERCLOS < self.status_Fatigue:\n",
    "            self.status = 0 # Fully_awake\n",
    "            self.PERCLOS_min = 0\n",
    "            self.PERCLOS_max = self.status_Fatigue\n",
    "            \n",
    "        elif (self.status_Fatigue <= self.PERCLOS) and (self.PERCLOS <= self.status_Drowsy):\n",
    "            self.status = 1 # Fatigue\n",
    "            self.PERCLOS_min = self.status_Fatigue\n",
    "            self.PERCLOS_max = self.status_Drowsy\n",
    "        \n",
    "        else:\n",
    "            self.status = 2 # Drowsy\n",
    "            self.PERCLOS_min = self.status_Drowsy\n",
    "            self.PERCLOS_max = 1\n",
    "        \n",
    "        perclos_scale = (self.PERCLOS - self.PERCLOS_min) / (self.PERCLOS_max - self.PERCLOS_min)\n",
    "        \n",
    "        self.level =round((perclos_scale*100), 2)\n",
    "        \n",
    "        return\n",
    "        \n",
    "       \n",
    "    def show_status(self, parameter_img):\n",
    "        \n",
    "        # 네모박스에 파라미터 띄우기\n",
    "        # 방법 : cv2.putText(image_original, text, (cx, cy),cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255))\n",
    "        \n",
    "        if self.status == 0:\n",
    "            cv2.putText(parameter_img, \"Awake\", (0, 50), cv2.FONT_HERSHEY_DUPLEX, 1, utils.RED,1)\n",
    "            cv2.putText(parameter_img, \"Fatique\", (200, 50), cv2.FONT_HERSHEY_DUPLEX, 1, utils.WHITE,1)\n",
    "            cv2.putText(parameter_img, \"Drowsy\", (400, 50), cv2.FONT_HERSHEY_DUPLEX, 1, utils.WHITE,1)\n",
    "\n",
    "        elif self.status == 1:\n",
    "            cv2.putText(parameter_img, \"Awake\", (0, 50), cv2.FONT_HERSHEY_DUPLEX, 1, utils.WHITE,1)\n",
    "            cv2.putText(parameter_img, \"Fatique\", (200, 50), cv2.FONT_HERSHEY_DUPLEX, 1, utils.RED,1)\n",
    "            cv2.putText(parameter_img, \"Drowsy\", (400, 50), cv2.FONT_HERSHEY_DUPLEX, 1, utils.WHITE,1)\n",
    "\n",
    "        else:\n",
    "            cv2.putText(parameter_img, \"Awake\", (0, 50), cv2.FONT_HERSHEY_DUPLEX, 1, utils.WHITE,1)\n",
    "            cv2.putText(parameter_img, \"Fatique\", (200, 50), cv2.FONT_HERSHEY_DUPLEX, 1, utils.WHITE,1)\n",
    "            cv2.putText(parameter_img, \"Drowsy\", (400, 50), cv2.FONT_HERSHEY_DUPLEX, 1, utils.RED,1)\n",
    "\n",
    "\n",
    "        # 띄울 파라미터들\n",
    "        now_ear = \"EAR : {}\".format(self.EAR)\n",
    "        perclos = \"PERCLOS : {}\".format(round((self.PERCLOS),2))\n",
    "        level = \"Level : {}%\".format(self.level)\n",
    "\n",
    "        cv2.putText(parameter_img, now_ear, (0, 150), cv2.FONT_HERSHEY_DUPLEX, 1.5, (255, 255, 255),1)\n",
    "        cv2.putText(parameter_img, perclos, (0, 250), cv2.FONT_HERSHEY_DUPLEX, 1.5, (255, 255, 255),1)\n",
    "        cv2.putText(parameter_img, level, (0, 350), cv2.FONT_HERSHEY_DUPLEX, 1.5, (255, 255, 255),1)\n",
    "           \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        self.__init__()\n",
    "        return\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22ce74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1eaa63ae",
   "metadata": {},
   "source": [
    "### main 문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2fc9409",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T11:11:21.443059Z",
     "start_time": "2023-11-27T11:10:08.728983Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "frame_counter = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "FONTS = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "dsm_model = detections()\n",
    "\n",
    "# 총 16\n",
    "left_eye = [362,382,381,380,374,373,390,249,263,466,388,387,386,385,384,398]\n",
    "right_eye =[ 33,  7,163,144,145,153,154,155,133,173,157,158,159,160,161,246] \n",
    "\n",
    "\n",
    "left_ear_p = [362,380,373,263,387,385]\n",
    "right_ear_p =[ 33,144,153,133,158,160] \n",
    "\n",
    "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        frame_counter += 1\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        \n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        results = face_mesh.process(rgb_frame)\n",
    "        parameter_img = np.zeros((512, 512, 3), np.uint8)\n",
    "        \n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            # 눈 색 채워서 표시하기\n",
    "            #frame = utils.fillPolyTrans(frame, [all_mesh_coords[p] for p in left_eye], utils.GREEN, opacity=0.8)\n",
    "            #frame = utils.fillPolyTrans(frame, [all_mesh_coords[p] for p in right_eye], utils.GREEN, opacity=0.8)\n",
    "            \n",
    "            \n",
    "            ########################################## 튜닝 공간  ##########################################\n",
    "            ################################################################################################\n",
    "            ################################################################################################\n",
    "            \n",
    "            # 1. 눈 좌표 추출            \n",
    "            left_eye_coords = dsm_model.landmarks_detection(frame, results, landmark=left_eye, draw=True)\n",
    "            right_eye_coords = dsm_model.landmarks_detection(frame, results, landmark=right_eye, draw=True)\n",
    "            \n",
    "            #tmp_L_ear = dsm_model.landmarks_detection(frame, results, colors=utils.RED, landmark=left_ear_p, draw=True)\n",
    "            #tmp_R_ear = dsm_model.landmarks_detection(frame, results, colors=utils.RED, landmark=right_ear_p, draw=True)\n",
    "            \n",
    "            # 2. ear계산 및 눈 깜빡임 판단\n",
    "            dsm_model.calculate_ear(left_eye_coords,right_eye_coords)\n",
    "            \n",
    "            # 3. perclos 계산\n",
    "            dsm_model.calculate_perclos()        \n",
    "            \n",
    "            # 4. level 계산\n",
    "            dsm_model.calculate_level()        \n",
    "\n",
    "            # 5. 파라미터 띄우기\n",
    "            dsm_model.show_status(parameter_img)\n",
    "\n",
    "            ################################################################################################\n",
    "            ################################################################################################\n",
    "            ################################################################################################\n",
    "            \n",
    "        \n",
    "        end_time = time.time() - start_time\n",
    "        fps = frame_counter/end_time\n",
    "        \n",
    "        frame = utils.textWithBackground(frame, f'FPS: {round(fps,1)}', FONTS, 1.0, (20,50), bgOpacity=0.9)\n",
    "        \n",
    "        cv2.imshow('Face mesh', frame)\n",
    "        cv2.imshow('parameter', parameter_img)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key==ord('q') or key==ord('Q'):\n",
    "            break\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c8079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6312f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242028eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_dsm",
   "language": "python",
   "name": "new_dsm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
