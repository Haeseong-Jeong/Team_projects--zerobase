{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9123bbf8",
   "metadata": {},
   "source": [
    "## 참고\n",
    "\n",
    "https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d7c09e",
   "metadata": {},
   "source": [
    "### dataset\n",
    "\n",
    " label    |     images <br>\n",
    "ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ <br>\n",
    " 졸음     |     a1, a2, a3 ....<br>\n",
    " 졸음     |     b1, b2, b3 ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355a2c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da66afe9",
   "metadata": {},
   "source": [
    "# 1. Train data 만들기\n",
    "\n",
    "1. 현재 데이터 구조\n",
    "    - drowsy, non drowy 폴더에 약 20명의 졸음, 정상 이미지가 serial 순으로 저장되어있음.\n",
    "\n",
    "2. 각 사람 별 이미지 개수 확인\n",
    "    - 개수가 천차 만별이라 600장(600frame)이상 있는 사람을 선별.\n",
    "    \n",
    "\n",
    "3. 시계열 이미지 파일이기 때문에 ConvLSTM2D 사용\n",
    "    - (샘플개수, 타임스텝, H, W, 채널)의 차원으로 input data를 생성해야함.\n",
    "    - 라벨을 같이 튜플로 묶어 fit_generator에 넣거나\n",
    "    - 라벨을 따로 만들어 fit에 넣는다\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add8f08",
   "metadata": {},
   "source": [
    "### 1 - 1. 수집 데이터 파악"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422cbb67",
   "metadata": {},
   "source": [
    "#### image 폴더명 (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67409249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:34:19.997339Z",
     "start_time": "2023-11-26T14:34:19.880831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Drowsy', 'Non Drowsy']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "target_class = os.listdir('../Data/Driver Drowsiness Dataset (DDD)/Original_dataset/')\n",
    "print(target_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3425f2a6",
   "metadata": {},
   "source": [
    "#### image data 사람 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af3d9e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:34:23.833571Z",
     "start_time": "2023-11-26T14:34:21.815532Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'S', 'ZC', 'L', 'J', 'A', 'K', 'Y', 'V', 'I', 'ZA', 'ZB', 'E', 'F', 'R', 'U', 'O', 'X', 'P', 'N', 'D', 'C', 'H', 'W', 'M', 'Q', 'G', 'B']\n",
      "['b', 'x', 'c', 'h', 'm', 'q', 'k', 'n', 'e', 'r', 'l', 's', 'u', 'zb', 'i', 'zc', 'w', 'd', 'p', 'j', 'a', 'g', 'za', 'v', 'y', 'o']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from glob import glob\n",
    "\n",
    "drowsy_data = glob('../Data/Driver Drowsiness Dataset (DDD)/Original_dataset/Drowsy/*.png')\n",
    "nondrowsy_data = glob('../Data/Driver Drowsiness Dataset (DDD)/Original_dataset/Non Drowsy/*.png')\n",
    "\n",
    "drowsy_img_class_list = []\n",
    "nondrowsy_img_class_list = []\n",
    "\n",
    "for data in drowsy_data:\n",
    "    \n",
    "    tmp = data.split('\\\\')[-1].split('.')[0]\n",
    "    new_str = re.sub(r\"[0-9]\", \"\", tmp)\n",
    "    \n",
    "    drowsy_img_class_list.append(new_str)\n",
    "    \n",
    "for data in nondrowsy_data:\n",
    "    \n",
    "    tmp = data.split('\\\\')[-1].split('.')[0]\n",
    "    new_str = re.sub(r\"[0-9]\", \"\", tmp)\n",
    "    \n",
    "    nondrowsy_img_class_list.append(new_str)\n",
    "\n",
    "drowsy_img_class = list(set(drowsy_img_class_list))\n",
    "nondrowsy_img_class = list(set(nondrowsy_img_class_list))\n",
    "\n",
    "print(drowsy_img_class)\n",
    "print(nondrowsy_img_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e141d",
   "metadata": {},
   "source": [
    "#### 사람 별 이미지 개수 ( 600장 이상만)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11972fa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:34:24.971416Z",
     "start_time": "2023-11-26T14:34:24.955375Z"
    }
   },
   "outputs": [],
   "source": [
    "drowsy_folder = '../Data/Driver Drowsiness Dataset (DDD)/Original_dataset/Drowsy/'\n",
    "nondrowsy_folder = '../Data/Driver Drowsiness Dataset (DDD)/Original_dataset/Non Drowsy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09602996",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:34:26.774457Z",
     "start_time": "2023-11-26T14:34:25.427481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "졸음 운전자 이미지 개수\n",
      "--------------------------------------------------\n",
      "T 총 개수 : 933\n",
      "ZC 총 개수 : 1346\n",
      "L 총 개수 : 732\n",
      "A 총 개수 : 1411\n",
      "K 총 개수 : 630\n",
      "Y 총 개수 : 1112\n",
      "V 총 개수 : 653\n",
      "I 총 개수 : 1095\n",
      "ZA 총 개수 : 621\n",
      "ZB 총 개수 : 1551\n",
      "E 총 개수 : 962\n",
      "O 총 개수 : 1097\n",
      "X 총 개수 : 1749\n",
      "P 총 개수 : 963\n",
      "N 총 개수 : 1156\n",
      "W 총 개수 : 1162\n",
      "M 총 개수 : 777\n"
     ]
    }
   ],
   "source": [
    "Drowsy_select_man = []\n",
    "\n",
    "print(\"졸음 운전자 이미지 개수\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for class_name in drowsy_img_class:\n",
    "    find_data = drowsy_folder + class_name + '*.png'\n",
    "    #print(find_data)\n",
    "    images = glob(find_data)\n",
    "    if len(images) > 600 :\n",
    "        print(f'{class_name} 총 개수 : {len(images)}')\n",
    "        Drowsy_select_man.append(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "340fe495",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:34:28.522119Z",
     "start_time": "2023-11-26T14:34:27.466847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정상 운전자 이미지 개수\n",
      "--------------------------------------------------\n",
      "x 총 개수 : 1143\n",
      "n 총 개수 : 957\n",
      "e 총 개수 : 1000\n",
      "zb 총 개수 : 1237\n",
      "i 총 개수 : 1045\n",
      "zc 총 개수 : 1288\n",
      "d 총 개수 : 1005\n",
      "j 총 개수 : 717\n",
      "a 총 개수 : 1252\n",
      "za 총 개수 : 1054\n",
      "v 총 개수 : 1002\n",
      "y 총 개수 : 1500\n",
      "o 총 개수 : 671\n"
     ]
    }
   ],
   "source": [
    "NonDrowsy_select_man = []\n",
    "\n",
    "print(\"정상 운전자 이미지 개수\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for class_name in nondrowsy_img_class:\n",
    "    find_data = nondrowsy_folder + class_name + '*.png'\n",
    "    #print(find_data)\n",
    "    images = glob(find_data)\n",
    "    #print(len(images))\n",
    "    if len(images) > 600 :\n",
    "        print(f'{class_name} 총 개수 : {len(images)}')\n",
    "        NonDrowsy_select_man.append(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc6809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1567fc7",
   "metadata": {},
   "source": [
    "#### train / validation 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00718eca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:34:29.836389Z",
     "start_time": "2023-11-26T14:34:29.828382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(Drowsy_select_man))\n",
    "print(len(NonDrowsy_select_man))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883a856f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:34:30.198567Z",
     "start_time": "2023-11-26T14:34:30.181530Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "13\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "train_num = int(len(Drowsy_select_man)*0.8)\n",
    "valid_num = len(Drowsy_select_man) - train_num\n",
    "\n",
    "print(len(Drowsy_select_man))\n",
    "print(train_num)\n",
    "print(valid_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d595e115",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:34:30.589936Z",
     "start_time": "2023-11-26T14:34:30.570919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "10\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "train_num = int(len(NonDrowsy_select_man)*0.8)\n",
    "valid_num = len(NonDrowsy_select_man) - train_num\n",
    "\n",
    "print(len(NonDrowsy_select_man))\n",
    "print(train_num)\n",
    "print(valid_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdee68a",
   "metadata": {},
   "source": [
    "#### ex) Nondrowsy 파일 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33428191",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:34:32.480129Z",
     "start_time": "2023-11-26T14:34:32.459117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'n', 'e', 'zb', 'i', 'zc', 'd', 'j', 'a', 'za', 'v', 'y', 'o']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NonDrowsy_select_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d805509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:34:33.041919Z",
     "start_time": "2023-11-26T14:34:33.029878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "n\n",
      "e\n",
      "zb\n",
      "i\n",
      "zc\n",
      "d\n",
      "j\n",
      "a\n",
      "za\n",
      "--\n",
      "v\n",
      "y\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "for i in range(train_num):\n",
    "    print(NonDrowsy_select_man[i])\n",
    "\n",
    "print('--')\n",
    "for j in range(train_num,len(NonDrowsy_select_man),1):\n",
    "    print(NonDrowsy_select_man[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013b78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94fdd212",
   "metadata": {},
   "source": [
    "#### 위 작업 그대로 train, validation data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a278086a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:37:26.529765Z",
     "start_time": "2023-11-26T14:34:38.562637Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, glob, numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "groups_folder_path = '../Data/Driver Drowsiness Dataset (DDD)/Original_dataset'\n",
    "categories = target_class            # [Drowsy, Non Drowsy] \n",
    "nb_classes = len(categories)         #카테고리갯수: 2개\n",
    "\n",
    "image_w = 40 #이미지의 크기를 모두 통일해준다\n",
    "image_h = 40\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "limit_frame = 600 # frame 수\n",
    "\n",
    "for idx, cat in enumerate(categories): # [Drowsy, Non Drowsy] \n",
    "    \n",
    "    #one-hot 돌리기.  \n",
    "    #label = [0 for i in range(nb_classes)] # one-hot으로 라벨을 붙혀줌\n",
    "    #label[idx] = 1\n",
    "    \n",
    "    if idx == 0:\n",
    "        for man in Drowsy_select_man:\n",
    "            \n",
    "            image_dir = groups_folder_path + \"/\" + cat + \"/\" + man + '*.png'\n",
    "            images = glob(image_dir)\n",
    "            \n",
    "            for image in images[:limit_frame]:\n",
    "                img = Image.open(image)      #폴더를 열어주고 이미지를 읽음\n",
    "\n",
    "                img = img.convert(\"RGB\")                  #RGB로 바꿈\n",
    "                img = img.resize((image_w, image_h))      #이미지 크기를 모두 학습시키기 쉽게 reshape\n",
    "                \n",
    "                data = np.asarray(img)    # 숫자 배열로 변환\n",
    "                data = data/255           # nomalization\n",
    "                X.append(data)   #리스트에 추가 \n",
    "                #y.append(label)\n",
    "            y.append(0)          #사람 별 라벨 추가\n",
    "     \n",
    "    else:\n",
    "        for man in NonDrowsy_select_man:\n",
    "                            \n",
    "            image_dir = groups_folder_path + \"/\" + cat + \"/\" + man + '*.png'\n",
    "            images = glob(image_dir)\n",
    "\n",
    "            for image in images[:limit_frame]:\n",
    "                img = Image.open(image)      #폴더를 열어주고 이미지를 읽음\n",
    "\n",
    "                img = img.convert(\"RGB\")                  #RGB로 바꿈\n",
    "                img = img.resize((image_w, image_h))      #이미지 크기를 모두 학습시키기 쉽게 reshape\n",
    "                \n",
    "                data = np.asarray(img)    # 숫자 배열로 변환\n",
    "                data = data/255           # nomalization\n",
    "                X.append(data)     #리스트에 추가\n",
    "                #y.append(label)\n",
    "            y.append(1)            #사람 별 라벨 추가\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03295f10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:37:33.878477Z",
     "start_time": "2023-11-26T14:37:33.609438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_step 없는 차원 :  (18000, 40, 40, 3)\n",
      "time_step 추가한 차원 :  (30, 600, 40, 40, 3)\n",
      "Y 라벨 개수 :  (30,)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array(X)\n",
    "print('time_step 없는 차원 : ', x_data.shape)\n",
    "\n",
    "x_data = x_data.reshape(-1,limit_frame,image_h,image_w,3)\n",
    "\n",
    "y_label = np.array(y)\n",
    "\n",
    "print('time_step 추가한 차원 : ', x_data.shape)\n",
    "print('Y 라벨 개수 : ', y_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6253a",
   "metadata": {},
   "source": [
    "#### train valid 분할\n",
    "\n",
    "             30 명\n",
    "         17명     13명\n",
    "       13명 4명  10명 3명\n",
    "       \n",
    "```\n",
    "           13명     +       10명\n",
    "train = x_data[:13] + x_data[17:27]\n",
    "\n",
    "    =>  [0,1,...12] + [17,18,...26]\n",
    "        \n",
    "            4명       +     3명\n",
    "valid = x_data[13:17] + x_data[27:]\n",
    "\n",
    "    =>  [13,14...16] + [27,28,29]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "610c8cfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:37:35.917770Z",
     "start_time": "2023-11-26T14:37:35.205528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data : (23, 600, 40, 40, 3)\n",
      "valid data : (7, 600, 40, 40, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate((x_data[:13],x_data[17:27]),axis=0)\n",
    "print('train data :',X_train.shape)\n",
    "\n",
    "X_test = np.concatenate((x_data[13:17],x_data[27:]),axis=0)\n",
    "print('valid data :',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dd3bf11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:37:37.126725Z",
     "start_time": "2023-11-26T14:37:37.073724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label : (23,)\n",
      "valid label : (7,)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.concatenate((y_label[:13],y_label[17:27]),axis=0)\n",
    "print('train label :',y_train.shape)\n",
    "\n",
    "y_test = np.concatenate((y_label[13:17],y_label[27:]),axis=0)\n",
    "print('valid label :',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d48638f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:37:56.273970Z",
     "start_time": "2023-11-26T14:37:56.258965Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import tensorflow as tf\n",
    "X_train = tf.constant(X_train)\n",
    "X_test = tf.constant(X_test)\n",
    "y_train = tf.constant(y_train)\n",
    "y_test = tf.constant(y_test)\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "022cfadc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:38:10.435055Z",
     "start_time": "2023-11-26T14:37:59.579483Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff192dcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T14:38:14.570074Z",
     "start_time": "2023-11-26T14:38:14.560078Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf \n",
    "from tensorflow.python.client import device_lib\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "517e731e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T15:03:18.480300Z",
     "start_time": "2023-11-26T15:03:17.926957Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d_28 (ConvLSTM2D)  (None, 600, 38, 38, 16)  11008     \n",
      "                                                                 \n",
      " max_pooling3d_20 (MaxPoolin  (None, 600, 19, 19, 16)  0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " time_distributed_20 (TimeDi  (None, 600, 19, 19, 16)  0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " conv_lstm2d_29 (ConvLSTM2D)  (None, 600, 17, 17, 16)  18496     \n",
      "                                                                 \n",
      " max_pooling3d_21 (MaxPoolin  (None, 600, 9, 9, 16)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " time_distributed_21 (TimeDi  (None, 600, 9, 9, 16)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " conv_lstm2d_30 (ConvLSTM2D)  (None, 600, 7, 7, 16)    18496     \n",
      "                                                                 \n",
      " max_pooling3d_22 (MaxPoolin  (None, 600, 4, 4, 16)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " time_distributed_22 (TimeDi  (None, 600, 4, 4, 16)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " conv_lstm2d_31 (ConvLSTM2D)  (None, 600, 2, 2, 16)    18496     \n",
      "                                                                 \n",
      " max_pooling3d_23 (MaxPoolin  (None, 600, 1, 1, 16)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " time_distributed_23 (TimeDi  (None, 600, 1, 1, 16)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 9600)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 19202     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,698\n",
      "Trainable params: 85,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(ConvLSTM2D(filters = 16, kernel_size=(3,3), activation='LeakyReLU', data_format='channels_last', return_sequences=True, recurrent_dropout=0.2, input_shape=(X_train.shape[1],X_train.shape[2], X_train.shape[3], 3)))\n",
    "model.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\n",
    "model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "model.add(ConvLSTM2D(filters = 16, kernel_size=(3,3), activation='LeakyReLU', data_format='channels_last', return_sequences=True, recurrent_dropout=0.2))\n",
    "model.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\n",
    "model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "model.add(ConvLSTM2D(filters = 16, kernel_size=(3,3), activation='LeakyReLU', data_format='channels_last', return_sequences=True, recurrent_dropout=0.2))\n",
    "model.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\n",
    "model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "model.add(ConvLSTM2D(filters = 16, kernel_size=(3,3), activation='LeakyReLU', data_format='channels_last', return_sequences=True, recurrent_dropout=0.2))\n",
    "model.add(MaxPooling3D(pool_size=(1,2,2), padding='same', data_format='channels_last'))\n",
    "model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "          \n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e265d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebe792a8",
   "metadata": {},
   "source": [
    "#### 컴파일 binary vs categorical ( 리스트 라벨 or 원 핫 인코딩 라벨)\n",
    "\n",
    "https://wikidocs.net/194135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76c7878e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T15:03:20.875187Z",
     "start_time": "2023-11-26T15:03:20.849250Z"
    }
   },
   "outputs": [],
   "source": [
    "#compile model\n",
    "\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df6d08e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T15:30:40.775892Z",
     "start_time": "2023-11-26T15:03:22.057467Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 493s 21s/step - loss: nan - accuracy: 0.6957 - val_loss: nan - val_accuracy: 0.5714\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 481s 21s/step - loss: nan - accuracy: 0.5652 - val_loss: nan - val_accuracy: 0.5714\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 456s 20s/step - loss: nan - accuracy: 0.5652 - val_loss: nan - val_accuracy: 0.5714\n",
      "Epoch 4/10\n",
      " 8/23 [=========>....................] - ETA: 5:47 - loss: nan - accuracy: 0.5000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Model training\u001b[39;00m\n\u001b[0;32m      2\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Yolo\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Yolo\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Yolo\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Yolo\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Yolo\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Yolo\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Yolo\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Yolo\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Yolo\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Model training\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    to_categorical(y_train),\n",
    "                    batch_size=1,\n",
    "                    epochs=10,\n",
    "                    validation_data=(X_test, to_categorical(y_test)),\n",
    "                    callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f0d31b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "606c444f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T15:30:46.896023Z",
     "start_time": "2023-11-26T15:30:46.563016Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy vs Epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend(loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the graph to check training and testing accuracy over the period of time\n",
    "plt.figure(figsize=(13,5))\n",
    "plt.title(\"Accuracy vs Epochs\")\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c40eddf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T03:08:24.490537Z",
     "start_time": "2023-11-26T03:08:23.477240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 956ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predicted_classes=[]\n",
    "for i in range(len(y_test)):\n",
    "    predicted_classes.append(np.argmax(y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86687ab7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T03:08:27.968240Z",
     "start_time": "2023-11-26T03:08:27.953248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Accuracy\n",
    "accuracy_score(y_test, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194df12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b375306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80de7860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T03:09:38.114313Z",
     "start_time": "2023-11-26T03:09:37.749416Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('LSTM_test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843c178",
   "metadata": {},
   "source": [
    "https://keras.io/examples/vision/conv_lstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6f7fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4dee50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac287b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yolo",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
